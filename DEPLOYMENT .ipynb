{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d770f52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohammed\n",
      "[nltk_data]     Arif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2024-04-23 10:01:14.420 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Mohammed Arif\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load NLTK resources if needed\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load data\n",
    "amazon = pd.read_csv(r'C:\\Users\\Mohammed Arif\\Downloads\\amazon_product.csv')\n",
    "\n",
    "# Initialize SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Tokenize and stem function\n",
    "def tokenize_stem(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    stem = [stemmer.stem(w) for w in tokens]\n",
    "    return \" \".join(stem)\n",
    "\n",
    "# Check if 'stemmed_tokens' column exists, otherwise create it\n",
    "if 'stemmed_tokens' not in amazon.columns:\n",
    "    amazon['stemmed_tokens'] = amazon.apply(lambda row: tokenize_stem(row['Title'] + ' ' + row['Description']), axis=1)\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=tokenize_stem)\n",
    "\n",
    "# Cosine similarity function\n",
    "def cosine_sim(txt1, txt2):\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([txt1, txt2])\n",
    "    return cosine_similarity(tfidf_matrix)[0][1]\n",
    "\n",
    "# Streamlit app\n",
    "def main():\n",
    "    st.title('Amazon Product Search')\n",
    "\n",
    "    # Sidebar input\n",
    "    query = st.text_input('Enter search query:')\n",
    "    if st.button('Search'):\n",
    "        st.write(f'Searching for: {query}')\n",
    "        results = search_product(query)\n",
    "        st.dataframe(results)\n",
    "\n",
    "# Search product function\n",
    "def search_product(query):\n",
    "    stemmed_query = tokenize_stem(query)\n",
    "    amazon['similarity'] = amazon['stemmed_tokens'].apply(lambda x: cosine_sim(stemmed_query, x))\n",
    "    res = amazon.sort_values(by=['similarity'], ascending=False).head(10)[['Title', 'Description', 'Category']]\n",
    "    return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dad7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "labeled_data = pd.read_csv(r'C:\\Users\\Mohammed Arif\\Downloads\\amazon_product.csv')\n",
    "\n",
    "\n",
    "def get_recommendations(data):\n",
    "    recommendations=amazon['stemmed_tokens']=amazon.apply(lambda row: tokenize_stem(row['Title']+ ' ' +row['Description']),axis=1)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "labeled_data['Predicted'] = labeled_data.apply(lambda row: get_recommendations(row), axis=1)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(labeled_data['Correct'], labeled_data['Predicted'])\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
